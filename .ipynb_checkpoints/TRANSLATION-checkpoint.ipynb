{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b987a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary =  \"Usually any machine learning or deep learning process has some similar steps, but in this case of terms of flow it is so simple any typical machine learning life Lord any process has some of the steps like collection of data set than building the model training the network evaluating the model and then predicting the outcome in case of tensorflow.Tensorflow bundles together a study of machine learning and deep learning models and algorithms and make them useful by way of common metaphor who will use machine learning and all of its products to improve the search engine the translation image captioning or the recommendations to give you a concrete example, Google users can experience a faster and more refined search with artificial intelligence.Each node in the graph represents a mathematical operation and each connection or Edge between the notes is a multi-dimensional data array or tensile test flow provides all of this for the programmer by way of the Python language by then is easy to learn and work with and provides convenient ways to express how high-level abstraction can be coupled together notes and the tensor in the tensorflow our python objects.China mobile is using tensorflow to improve their success rate of the network element cut overs Channel while has created a deep Fist amusing tensorflow that can automatically predicts the cut over time window verify log operations and detect Network anomalies and this has already successfully supported the world's largest relocation of hundreds of millions iot HSS.is training a neural network to identify specific anatomic during the brain MRI exam to help improve speed and reliability now PayPal is using it as a flow to stay at The Cutting Edge of fraud detection using tensorflow deep trance for Learning and Generator modeling PayPalCNTK the Microsoft cognitive toolkit, like tensorflow uses a graph structure to describe the data flow, but it focuses more on creating deep learningIt is also in the market another thing that gives tensorflow Edge over other competitors is the fact that it is open source and has a huge Community Support that not only provides researchers a way to build new models, but also a platform to interact with others that face some issues if we talk about a simple program in terms of flow.Thanks to machine learning Frameworks such as Google's TensorFlow that ease the process of acquiring data, training model, solving predictions and refining future results.The Airbnb ingenious and data science team applies machine learning using tensorflow to classify the images and detect objects at scale helping to improve the guest experienceYou can build and train models by using the high-level Kira's API, which makes getting started with tensorflow and machine learning very very easy.Now the actual math operations however are not performed in Python the libraries of transformation data available through tears flow are written as high performance C++ binaries python just directs the traffic between the pieces and provides high level programming attraction to hook them together now building a new rail.Machine learning is a complex discipline but implementing machine learning models is far less daunting and difficult than it used to be.There's a flow allows the developers to create a data flow graphs which are structures that describe how the data move through a graph or a series of processing nodes.Created by the Google brain team tensorflow is an open source library for numerical computation and large scale machine learning.The model is also a single line of code now training a neural network cannot get any more easier than this and that is why it is the flow remains at the top when compared to the other competitors.No talking about Apache MXNet adopted by Amazon as a premier deep learning framework on AWS can scale almost linearly across multiple gpus and multiple machine.If you need more flexibility Iker execution allows for immediate iteration and intuitive debugging when you enable eager execution, you will be executing tensorflow kernels immediately rather than constructing graphs that will be executed laterThe network is just a single line evaluating the network or the model itself is a single line of code and predicting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083a4094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from deep-translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9d9be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "     ---------------------- ----------------- 30.7/55.1 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 55.1/55.1 kB 575.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.5/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.5/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.5/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 53.6/53.6 kB ? eta 0:00:00\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.0/65.0 kB ? eta 0:00:00\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15777 sha256=53ead3af5b16136d4efa6efe8480bf9128b9a9cf42bf2b83279e3e7972975c2c\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\a0\\a7\\f5\\8029729ab74f860fab6614e312b0aa48b665d1057280bc2ef3\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1597e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340175ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from deep_translator import MicrosoftTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHECK OUT YOUR SOURCE LANGUAGE FROM BELOW:\")\n",
    "print(\" \")\n",
    "langdict=googletrans.LANGUAGES\n",
    "for i in langdict :\n",
    "    print(i+\"-\" +langdict[i])\n",
    "srclang=input(\"ENTER LANGUAGE CODE: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d0f139",
   "metadata": {},
   "outputs": [
    {
     "ename": "LanguageNotSupportedException",
     "evalue": "hello --> No support for the provided language.\nPlease select on of the supported languages:\n{'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu', 'belarusian': 'be', 'bengali': 'bn', 'bhojpuri': 'bho', 'bosnian': 'bs', 'bulgarian': 'bg', 'catalan': 'ca', 'cebuano': 'ceb', 'chichewa': 'ny', 'chinese (simplified)': 'zh-CN', 'chinese (traditional)': 'zh-TW', 'corsican': 'co', 'croatian': 'hr', 'czech': 'cs', 'danish': 'da', 'dhivehi': 'dv', 'dogri': 'doi', 'dutch': 'nl', 'english': 'en', 'esperanto': 'eo', 'estonian': 'et', 'ewe': 'ee', 'filipino': 'tl', 'finnish': 'fi', 'french': 'fr', 'frisian': 'fy', 'galician': 'gl', 'georgian': 'ka', 'german': 'de', 'greek': 'el', 'guarani': 'gn', 'gujarati': 'gu', 'haitian creole': 'ht', 'hausa': 'ha', 'hawaiian': 'haw', 'hebrew': 'iw', 'hindi': 'hi', 'hmong': 'hmn', 'hungarian': 'hu', 'icelandic': 'is', 'igbo': 'ig', 'ilocano': 'ilo', 'indonesian': 'id', 'irish': 'ga', 'italian': 'it', 'japanese': 'ja', 'javanese': 'jw', 'kannada': 'kn', 'kazakh': 'kk', 'khmer': 'km', 'kinyarwanda': 'rw', 'konkani': 'gom', 'korean': 'ko', 'krio': 'kri', 'kurdish (kurmanji)': 'ku', 'kurdish (sorani)': 'ckb', 'kyrgyz': 'ky', 'lao': 'lo', 'latin': 'la', 'latvian': 'lv', 'lingala': 'ln', 'lithuanian': 'lt', 'luganda': 'lg', 'luxembourgish': 'lb', 'macedonian': 'mk', 'maithili': 'mai', 'malagasy': 'mg', 'malay': 'ms', 'malayalam': 'ml', 'maltese': 'mt', 'maori': 'mi', 'marathi': 'mr', 'meiteilon (manipuri)': 'mni-Mtei', 'mizo': 'lus', 'mongolian': 'mn', 'myanmar': 'my', 'nepali': 'ne', 'norwegian': 'no', 'odia (oriya)': 'or', 'oromo': 'om', 'pashto': 'ps', 'persian': 'fa', 'polish': 'pl', 'portuguese': 'pt', 'punjabi': 'pa', 'quechua': 'qu', 'romanian': 'ro', 'russian': 'ru', 'samoan': 'sm', 'sanskrit': 'sa', 'scots gaelic': 'gd', 'sepedi': 'nso', 'serbian': 'sr', 'sesotho': 'st', 'shona': 'sn', 'sindhi': 'sd', 'sinhala': 'si', 'slovak': 'sk', 'slovenian': 'sl', 'somali': 'so', 'spanish': 'es', 'sundanese': 'su', 'swahili': 'sw', 'swedish': 'sv', 'tajik': 'tg', 'tamil': 'ta', 'tatar': 'tt', 'telugu': 'te', 'thai': 'th', 'tigrinya': 'ti', 'tsonga': 'ts', 'turkish': 'tr', 'turkmen': 'tk', 'twi': 'ak', 'ukrainian': 'uk', 'urdu': 'ur', 'uyghur': 'ug', 'uzbek': 'uz', 'vietnamese': 'vi', 'welsh': 'cy', 'xhosa': 'xh', 'yiddish': 'yi', 'yoruba': 'yo', 'zulu': 'zu'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLanguageNotSupportedException\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m to_translate \u001b[38;5;241m=\u001b[39m summary \n\u001b[1;32m----> 2\u001b[0m translated \u001b[38;5;241m=\u001b[39m GoogleTranslator(source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m , target \u001b[38;5;241m=\u001b[39m srclang )\u001b[38;5;241m.\u001b[39mtranslate(to_translate)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR TRANSLATED SUMMARY IS GIVEN BELOW:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\google.py:39\u001b[0m, in \u001b[0;36mGoogleTranslator.__init__\u001b[1;34m(self, source, target, proxies, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m@param source: source language to translate from\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m@param target: target language to translate to\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies \u001b[38;5;241m=\u001b[39m proxies\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     40\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mBASE_URLS\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_TRANSLATE\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     41\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[0;32m     42\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m     43\u001b[0m     element_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     element_query\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt0\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     45\u001b[0m     payload_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# key of text in the url\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alt_element_query \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult-container\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\base.py:44\u001b[0m, in \u001b[0;36mBaseTranslator.__init__\u001b[1;34m(self, base_url, languages, source, target, payload_key, element_tag, element_query, **url_params)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidSourceOrTargetLanguage(target)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_source, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_language_to_code(source, target)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_params \u001b[38;5;241m=\u001b[39m url_params\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_tag \u001b[38;5;241m=\u001b[39m element_tag\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deep_translator\\base.py:84\u001b[0m, in \u001b[0;36mBaseTranslator._map_language_to_code\u001b[1;34m(self, *languages)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_languages[language]\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LanguageNotSupportedException(\n\u001b[0;32m     85\u001b[0m         language,\n\u001b[0;32m     86\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for the provided language.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select on of the supported languages:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_languages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m     )\n",
      "\u001b[1;31mLanguageNotSupportedException\u001b[0m: hello --> No support for the provided language.\nPlease select on of the supported languages:\n{'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu', 'belarusian': 'be', 'bengali': 'bn', 'bhojpuri': 'bho', 'bosnian': 'bs', 'bulgarian': 'bg', 'catalan': 'ca', 'cebuano': 'ceb', 'chichewa': 'ny', 'chinese (simplified)': 'zh-CN', 'chinese (traditional)': 'zh-TW', 'corsican': 'co', 'croatian': 'hr', 'czech': 'cs', 'danish': 'da', 'dhivehi': 'dv', 'dogri': 'doi', 'dutch': 'nl', 'english': 'en', 'esperanto': 'eo', 'estonian': 'et', 'ewe': 'ee', 'filipino': 'tl', 'finnish': 'fi', 'french': 'fr', 'frisian': 'fy', 'galician': 'gl', 'georgian': 'ka', 'german': 'de', 'greek': 'el', 'guarani': 'gn', 'gujarati': 'gu', 'haitian creole': 'ht', 'hausa': 'ha', 'hawaiian': 'haw', 'hebrew': 'iw', 'hindi': 'hi', 'hmong': 'hmn', 'hungarian': 'hu', 'icelandic': 'is', 'igbo': 'ig', 'ilocano': 'ilo', 'indonesian': 'id', 'irish': 'ga', 'italian': 'it', 'japanese': 'ja', 'javanese': 'jw', 'kannada': 'kn', 'kazakh': 'kk', 'khmer': 'km', 'kinyarwanda': 'rw', 'konkani': 'gom', 'korean': 'ko', 'krio': 'kri', 'kurdish (kurmanji)': 'ku', 'kurdish (sorani)': 'ckb', 'kyrgyz': 'ky', 'lao': 'lo', 'latin': 'la', 'latvian': 'lv', 'lingala': 'ln', 'lithuanian': 'lt', 'luganda': 'lg', 'luxembourgish': 'lb', 'macedonian': 'mk', 'maithili': 'mai', 'malagasy': 'mg', 'malay': 'ms', 'malayalam': 'ml', 'maltese': 'mt', 'maori': 'mi', 'marathi': 'mr', 'meiteilon (manipuri)': 'mni-Mtei', 'mizo': 'lus', 'mongolian': 'mn', 'myanmar': 'my', 'nepali': 'ne', 'norwegian': 'no', 'odia (oriya)': 'or', 'oromo': 'om', 'pashto': 'ps', 'persian': 'fa', 'polish': 'pl', 'portuguese': 'pt', 'punjabi': 'pa', 'quechua': 'qu', 'romanian': 'ro', 'russian': 'ru', 'samoan': 'sm', 'sanskrit': 'sa', 'scots gaelic': 'gd', 'sepedi': 'nso', 'serbian': 'sr', 'sesotho': 'st', 'shona': 'sn', 'sindhi': 'sd', 'sinhala': 'si', 'slovak': 'sk', 'slovenian': 'sl', 'somali': 'so', 'spanish': 'es', 'sundanese': 'su', 'swahili': 'sw', 'swedish': 'sv', 'tajik': 'tg', 'tamil': 'ta', 'tatar': 'tt', 'telugu': 'te', 'thai': 'th', 'tigrinya': 'ti', 'tsonga': 'ts', 'turkish': 'tr', 'turkmen': 'tk', 'twi': 'ak', 'ukrainian': 'uk', 'urdu': 'ur', 'uyghur': 'ug', 'uzbek': 'uz', 'vietnamese': 'vi', 'welsh': 'cy', 'xhosa': 'xh', 'yiddish': 'yi', 'yoruba': 'yo', 'zulu': 'zu'}"
     ]
    }
   ],
   "source": [
    "to_translate = summary \n",
    "translated = GoogleTranslator(source = 'auto' , target = srclang ).translate(to_translate)\n",
    "print(\"YOUR TRANSLATED SUMMARY IS GIVEN BELOW:\")\n",
    "print(\" \")\n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cef41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
