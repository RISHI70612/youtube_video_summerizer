{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b987a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary =  \"Usually any machine learning or deep learning process has some similar steps, but in this case of terms of flow it is so simple any typical machine learning life Lord any process has some of the steps like collection of data set than building the model training the network evaluating the model and then predicting the outcome in case of tensorflow.Tensorflow bundles together a study of machine learning and deep learning models and algorithms and make them useful by way of common metaphor who will use machine learning and all of its products to improve the search engine the translation image captioning or the recommendations to give you a concrete example, Google users can experience a faster and more refined search with artificial intelligence.Each node in the graph represents a mathematical operation and each connection or Edge between the notes is a multi-dimensional data array or tensile test flow provides all of this for the programmer by way of the Python language by then is easy to learn and work with and provides convenient ways to express how high-level abstraction can be coupled together notes and the tensor in the tensorflow our python objects.China mobile is using tensorflow to improve their success rate of the network element cut overs Channel while has created a deep Fist amusing tensorflow that can automatically predicts the cut over time window verify log operations and detect Network anomalies and this has already successfully supported the world's largest relocation of hundreds of millions iot HSS.is training a neural network to identify specific anatomic during the brain MRI exam to help improve speed and reliability now PayPal is using it as a flow to stay at The Cutting Edge of fraud detection using tensorflow deep trance for Learning and Generator modeling PayPalCNTK the Microsoft cognitive toolkit, like tensorflow uses a graph structure to describe the data flow, but it focuses more on creating deep learningIt is also in the market another thing that gives tensorflow Edge over other competitors is the fact that it is open source and has a huge Community Support that not only provides researchers a way to build new models, but also a platform to interact with others that face some issues if we talk about a simple program in terms of flow.Thanks to machine learning Frameworks such as Google's TensorFlow that ease the process of acquiring data, training model, solving predictions and refining future results.The Airbnb ingenious and data science team applies machine learning using tensorflow to classify the images and detect objects at scale helping to improve the guest experienceYou can build and train models by using the high-level Kira's API, which makes getting started with tensorflow and machine learning very very easy.Now the actual math operations however are not performed in Python the libraries of transformation data available through tears flow are written as high performance C++ binaries python just directs the traffic between the pieces and provides high level programming attraction to hook them together now building a new rail.Machine learning is a complex discipline but implementing machine learning models is far less daunting and difficult than it used to be.There's a flow allows the developers to create a data flow graphs which are structures that describe how the data move through a graph or a series of processing nodes.Created by the Google brain team tensorflow is an open source library for numerical computation and large scale machine learning.The model is also a single line of code now training a neural network cannot get any more easier than this and that is why it is the flow remains at the top when compared to the other competitors.No talking about Apache MXNet adopted by Amazon as a premier deep learning framework on AWS can scale almost linearly across multiple gpus and multiple machine.If you need more flexibility Iker execution allows for immediate iteration and intuitive debugging when you enable eager execution, you will be executing tensorflow kernels immediately rather than constructing graphs that will be executed laterThe network is just a single line evaluating the network or the model itself is a single line of code and predicting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083a4094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from deep-translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9d9be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "     ---------------------- ----------------- 30.7/55.1 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 55.1/55.1 kB 575.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.5/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.5/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.5/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 53.6/53.6 kB ? eta 0:00:00\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.0/65.0 kB ? eta 0:00:00\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15777 sha256=53ead3af5b16136d4efa6efe8480bf9128b9a9cf42bf2b83279e3e7972975c2c\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\a0\\a7\\f5\\8029729ab74f860fab6614e312b0aa48b665d1057280bc2ef3\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1597e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "340175ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from deep_translator import MicrosoftTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3f1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK OUT YOUR SOURCE LANGUAGE FROM BELOW:\n",
      " \n",
      "af-afrikaans\n",
      "sq-albanian\n",
      "am-amharic\n",
      "ar-arabic\n",
      "hy-armenian\n",
      "az-azerbaijani\n",
      "eu-basque\n",
      "be-belarusian\n",
      "bn-bengali\n",
      "bs-bosnian\n",
      "bg-bulgarian\n",
      "ca-catalan\n",
      "ceb-cebuano\n",
      "ny-chichewa\n",
      "zh-cn-chinese (simplified)\n",
      "zh-tw-chinese (traditional)\n",
      "co-corsican\n",
      "hr-croatian\n",
      "cs-czech\n",
      "da-danish\n",
      "nl-dutch\n",
      "en-english\n",
      "eo-esperanto\n",
      "et-estonian\n",
      "tl-filipino\n",
      "fi-finnish\n",
      "fr-french\n",
      "fy-frisian\n",
      "gl-galician\n",
      "ka-georgian\n",
      "de-german\n",
      "el-greek\n",
      "gu-gujarati\n",
      "ht-haitian creole\n",
      "ha-hausa\n",
      "haw-hawaiian\n",
      "iw-hebrew\n",
      "he-hebrew\n",
      "hi-hindi\n",
      "hmn-hmong\n",
      "hu-hungarian\n",
      "is-icelandic\n",
      "ig-igbo\n",
      "id-indonesian\n",
      "ga-irish\n",
      "it-italian\n",
      "ja-japanese\n",
      "jw-javanese\n",
      "kn-kannada\n",
      "kk-kazakh\n",
      "km-khmer\n",
      "ko-korean\n",
      "ku-kurdish (kurmanji)\n",
      "ky-kyrgyz\n",
      "lo-lao\n",
      "la-latin\n",
      "lv-latvian\n",
      "lt-lithuanian\n",
      "lb-luxembourgish\n",
      "mk-macedonian\n",
      "mg-malagasy\n",
      "ms-malay\n",
      "ml-malayalam\n",
      "mt-maltese\n",
      "mi-maori\n",
      "mr-marathi\n",
      "mn-mongolian\n",
      "my-myanmar (burmese)\n",
      "ne-nepali\n",
      "no-norwegian\n",
      "or-odia\n",
      "ps-pashto\n",
      "fa-persian\n",
      "pl-polish\n",
      "pt-portuguese\n",
      "pa-punjabi\n",
      "ro-romanian\n",
      "ru-russian\n",
      "sm-samoan\n",
      "gd-scots gaelic\n",
      "sr-serbian\n",
      "st-sesotho\n",
      "sn-shona\n",
      "sd-sindhi\n",
      "si-sinhala\n",
      "sk-slovak\n",
      "sl-slovenian\n",
      "so-somali\n",
      "es-spanish\n",
      "su-sundanese\n",
      "sw-swahili\n",
      "sv-swedish\n",
      "tg-tajik\n",
      "ta-tamil\n",
      "te-telugu\n",
      "th-thai\n",
      "tr-turkish\n",
      "uk-ukrainian\n",
      "ur-urdu\n",
      "ug-uyghur\n",
      "uz-uzbek\n",
      "vi-vietnamese\n",
      "cy-welsh\n",
      "xh-xhosa\n",
      "yi-yiddish\n",
      "yo-yoruba\n",
      "zu-zulu\n",
      "ENTER LANGUAGE CODE: te\n"
     ]
    }
   ],
   "source": [
    "print(\"CHECK OUT YOUR SOURCE LANGUAGE FROM BELOW:\")\n",
    "print(\" \")\n",
    "langdict=googletrans.LANGUAGES\n",
    "for i in langdict :\n",
    "    print(i+\"-\" +langdict[i])\n",
    "srclang=input(\"ENTER LANGUAGE CODE: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d0f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR TRANSLATED SUMMARY IS GIVEN BELOW:\n",
      " \n",
      "సాధారణంగా ఏదైనా మెషీన్ లెర్నింగ్ లేదా డీప్ లెర్నింగ్ ప్రాసెస్‌లో కొన్ని సారూప్య దశలు ఉంటాయి, అయితే ఈ ఫ్లో పరంగా ఇది చాలా సులభం ఏదైనా సాధారణ మెషీన్ లెర్నింగ్ లైఫ్ లార్డ్ ఏదైనా ప్రక్రియలో నెట్‌వర్క్ శిక్షణ మోడల్‌ను రూపొందించడం కంటే డేటా సెట్ సేకరణ వంటి కొన్ని దశలు ఉంటాయి. మోడల్‌ను మూల్యాంకనం చేసి, ఆపై టెన్సర్‌ఫ్లో విషయంలో ఫలితాన్ని అంచనా వేస్తుంది. టెన్సార్‌ఫ్లో మెషీన్ లెర్నింగ్ మరియు డీప్ లెర్నింగ్ మోడల్‌లు మరియు అల్గారిథమ్‌ల అధ్యయనాన్ని ఒకదానితో ఒకటి కలుపుతుంది మరియు శోధనను మెరుగుపరచడానికి మెషీన్ లెర్నింగ్ మరియు దాని అన్ని ఉత్పత్తులను ఉపయోగించే సాధారణ రూపకం ద్వారా వాటిని ఉపయోగకరంగా చేస్తుంది అనువాద చిత్రం క్యాప్షనింగ్ లేదా మీకు నిర్దిష్ట ఉదాహరణను అందించడానికి సిఫార్సులు, Google వినియోగదారులు కృత్రిమ మేధస్సుతో వేగవంతమైన మరియు మరింత శుద్ధి చేసిన శోధనను అనుభవించవచ్చు.గ్రాఫ్‌లోని ప్రతి నోడ్ గణిత ఆపరేషన్‌ను సూచిస్తుంది మరియు గమనికల మధ్య ప్రతి కనెక్షన్ లేదా ఎడ్జ్ బహుళ- డైమెన్షనల్ డేటా అర్రే లేదా టెన్సైల్ టెస్ట్ ఫ్లో ప్రోగ్రామర్‌కి పైథాన్ భాష ద్వారా వీటన్నింటిని అందిస్తుంది, అప్పటికి నేర్చుకోవడం మరియు పని చేయడం సులభం మరియు గమనికలు మరియు టెన్సర్‌తో కలిసి ఉన్నత-స్థాయి సంగ్రహణ ఎలా ఉండవచ్చో వ్యక్తీకరించడానికి అనుకూలమైన మార్గాలను అందిస్తుంది. tensorflow మా పైథాన్ ఆబ్జెక్ట్‌లను tensorflow.చైనా మొబైల్ నెట్‌వర్క్ ఎలిమెంట్ కట్ ఓవర్‌ల ఛానెల్ యొక్క సక్సెస్ రేట్‌ను మెరుగుపరచడానికి టెన్సర్‌ఫ్లోను ఉపయోగిస్తోంది, అయితే కాలక్రమేణా కట్‌ను స్వయంచాలకంగా అంచనా వేయగల లోతైన ఫిస్ట్ వినోదభరితమైన టెన్సర్‌ఫ్లోను సృష్టించింది, ఇది లాగ్ ఆపరేషన్‌లను తనిఖీ చేస్తుంది మరియు నెట్‌వర్క్ క్రమరాహిత్యాలను గుర్తించగలదు మరియు ఇది ఇప్పటికే ఉంది వందల మిలియన్ల మంది ఐఓటీ HSS ప్రపంచంలోనే అతిపెద్ద పునరావాసానికి విజయవంతంగా మద్దతునిచ్చింది. మెదడు MRI పరీక్ష సమయంలో నిర్దిష్ట శరీర నిర్మాణ శాస్త్రాన్ని గుర్తించడానికి ఒక న్యూరల్ నెట్‌వర్క్‌కు శిక్షణనిస్తోంది, ఇది వేగం మరియు విశ్వసనీయతను మెరుగుపరచడంలో సహాయపడుతుంది. లెర్నింగ్ మరియు జనరేటర్ మోడలింగ్ కోసం PayPalCNTK మైక్రోసాఫ్ట్ కాగ్నిటివ్ టూల్‌కిట్ టెన్సార్‌ఫ్లో డీప్ ట్రాన్స్‌ని ఉపయోగించడం, డేటా ఫ్లోను వివరించడానికి టెన్సార్‌ఫ్లో గ్రాఫ్ స్ట్రక్చర్‌ను ఉపయోగిస్తుంది, అయితే ఇది లోతైన అభ్యాసాన్ని సృష్టించడంపై ఎక్కువ దృష్టి పెడుతుంది, ఇది మార్కెట్‌లో ఇతర పోటీదారుల కంటే టెన్సర్‌ఫ్లో ఎడ్జ్‌ని అందించే మరొక విషయం. ఇది ఓపెన్ సోర్స్ మరియు భారీ కమ్యూనిటీ మద్దతును కలిగి ఉంది, ఇది పరిశోధకులకు కొత్త మోడల్‌లను రూపొందించడానికి ఒక మార్గాన్ని అందించడమే కాకుండా, మేము ఫ్లో పరంగా ఒక సాధారణ ప్రోగ్రామ్ గురించి మాట్లాడినట్లయితే కొన్ని సమస్యలను ఎదుర్కొనే ఇతరులతో ఇంటరాక్ట్ అయ్యే ప్లాట్‌ఫారమ్‌ను కూడా అందిస్తుంది. ధన్యవాదాలు డేటాను పొందడం, శిక్షణా నమూనా, అంచనాలను పరిష్కరించడం మరియు భవిష్యత్తు ఫలితాలను మెరుగుపరచడం వంటి ప్రక్రియలను సులభతరం చేసే Google యొక్క TensorFlow వంటి మెషిన్ లెర్నింగ్ ఫ్రేమ్‌వర్క్‌లకు. Airbnb తెలివిగల మరియు డేటా సైన్స్ బృందం చిత్రాలను వర్గీకరించడానికి మరియు మెరుగుపరచడంలో సహాయపడే స్కేల్‌లో వస్తువులను గుర్తించడానికి టెన్సర్‌ఫ్లో ఉపయోగించి మెషిన్ లెర్నింగ్‌ను వర్తింపజేస్తుంది. అతిథి అనుభవం మీరు అధిక-స్థాయి Kira APIని ఉపయోగించడం ద్వారా మోడల్‌లను రూపొందించవచ్చు మరియు శిక్షణ ఇవ్వవచ్చు, ఇది టెన్సర్‌ఫ్లో మరియు మెషిన్ లెర్నింగ్‌తో ప్రారంభించడం చాలా సులభం చేస్తుంది. అయితే ఇప్పుడు అసలు గణిత కార్యకలాపాలు పైథాన్‌లో నిర్వహించబడవు, అయితే కన్నీటి ప్రవాహం ద్వారా లభించే పరివర్తన డేటా లైబ్రరీలు అందుబాటులో ఉంటాయి. అధిక పనితీరు C++ బైనరీస్ పైథాన్ ముక్కల మధ్య ట్రాఫిక్‌ను నిర్దేశిస్తుంది మరియు ఇప్పుడు కొత్త రైలును నిర్మించడం ద్వారా వాటిని కట్టిపడేసేందుకు ఉన్నత స్థాయి ప్రోగ్రామింగ్ ఆకర్షణను అందిస్తుంది. మెషిన్ లెర్నింగ్ అనేది ఒక సంక్లిష్టమైన క్రమశిక్షణ, అయితే మెషిన్ లెర్నింగ్ మోడల్‌లను అమలు చేయడం దాని కంటే చాలా తక్కువ భయంకరమైనది మరియు కష్టం. ఉపయోగించినది.ఒక గ్రాఫ్ లేదా ప్రాసెసింగ్ నోడ్‌ల శ్రేణి ద్వారా డేటా ఎలా కదులుతుందో వివరించే నిర్మాణాలు అయిన డేటా ఫ్లో గ్రాఫ్‌లను రూపొందించడానికి డెవలపర్‌లను అనుమతిస్తుంది. మరియు పెద్ద ఎత్తున మెషిన్ లెర్నింగ్. మోడల్ కూడా ఇప్పుడు ఒక న్యూరల్ నెట్‌వర్క్‌కి శిక్షణనిచ్చే సింగిల్ లైన్ కోడ్, దీని కంటే సులభంగా పొందలేము మరియు అందుకే ఇతర పోటీదారులతో పోల్చినప్పుడు ప్రవాహం ఎగువన ఉంటుంది. అపాచీ గురించి మాట్లాడటం లేదు. AWSలో ప్రధాన డీప్ లెర్నింగ్ ఫ్రేమ్‌వర్క్‌గా Amazon చేత స్వీకరించబడిన MXNet బహుళ gpus మరియు బహుళ మెషీన్‌లలో దాదాపు సరళంగా స్కేల్ చేయగలదు. మీకు మరింత సౌలభ్యం కావాలంటే Iker ఎగ్జిక్యూషన్ తక్షణ పునరుక్తిని మరియు సహజమైన డీబగ్గింగ్‌ను మీరు ఆసక్తిగా అమలు చేయడానికి అనుమతిస్తుంది, మీరు వెంటనే టెన్సార్‌ఫ్లో కెర్నల్‌లను అమలు చేస్తారు. తరువాత అమలు చేయబడే గ్రాఫ్‌లను నిర్మించడం కంటే నెట్‌వర్క్ అనేది నెట్‌వర్క్‌ను మూల్యాంకనం చేసే ఒకే లైన్ లేదా మోడల్ కూడా ఒకే లైన్ కోడ్ మరియు అంచనా\n"
     ]
    }
   ],
   "source": [
    "to_translate = summary \n",
    "translated = GoogleTranslator(source = 'auto' , target = srclang ).translate(to_translate)\n",
    "print(\"YOUR TRANSLATED SUMMARY IS GIVEN BELOW:\")\n",
    "print(\" \")\n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2cef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1799c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the below option:\n",
      " \n",
      "E for converting extracted summary to speech.\n",
      "T for converting translated summary to speech.\n",
      "B for converting both translated and extracted summary to speech.\n",
      "Enter your choice: T\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose the below option:\")\n",
    "print(\" \")\n",
    "print(\"E for converting extracted summary to speech.\\n\" \"T for converting translated summary to speech.\\n\" \"B for converting both translated and extracted summary to speech.\")\n",
    "option=input(\"Enter your choice: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a6f6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of Translated Summary file: Translated\n"
     ]
    }
   ],
   "source": [
    "if option=='E' or option=='e':\n",
    "  speechtext=summary\n",
    "  speech1=gtts.gTTS(speechtext)\n",
    "  name1=input(\"Enter name of Extracted Summary file: \")\n",
    "  speech1.save(name1+\".mp3\")\n",
    "\n",
    "elif option=='T' or option=='t':\n",
    "  speechtext=translated\n",
    "  speech1=gtts.gTTS(speechtext)\n",
    "  name2=input(\"Enter name of Translated Summary file: \")\n",
    "  speech1.save(name2+\".mp3\")\n",
    "\n",
    "elif option=='B' or option=='b':\n",
    "  speechtext1=summary\n",
    "  speechtext2=translated\n",
    "  speech1=gtts.gTTS(speechtext1)\n",
    "  speech2=gtts.gTTS(speechtext2)\n",
    "  name1=input(\"Enter name of Extracted Summary file: \")\n",
    "  name2=input(\"Enter name of Translated Summary file: \")\n",
    "  speech1.save(name1+\".mp3\")\n",
    "  speech2.save(name2+\".mp3\")\n",
    "\n",
    "else:\n",
    "  print(\"Invalid Option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a869a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
